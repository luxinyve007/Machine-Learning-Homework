{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Objective</a></span></li><li><span><a href=\"#Data-Processing\" data-toc-modified-id=\"Data-Processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Remove-column-'name'\" data-toc-modified-id=\"Remove-column-'name'-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Remove column 'name'</a></span></li><li><span><a href=\"#Handling-missing-value\" data-toc-modified-id=\"Handling-missing-value-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Handling missing value</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-missing-value-checker\" data-toc-modified-id=\"The-missing-value-checker-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>The missing value checker</a></span></li><li><span><a href=\"#Identify-variables-with-missing-values\" data-toc-modified-id=\"Identify-variables-with-missing-values-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Identify variables with missing values</a></span></li></ul></li><li><span><a href=\"#Get-the-features-and-target\" data-toc-modified-id=\"Get-the-features-and-target-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Get the features and target</a></span></li><li><span><a href=\"#Handling-categorical-features\" data-toc-modified-id=\"Handling-categorical-features-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Handling categorical features</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-categorical-feature-checker\" data-toc-modified-id=\"The-categorical-feature-checker-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>The categorical feature checker</a></span></li><li><span><a href=\"#Identify-categorical-features\" data-toc-modified-id=\"Identify-categorical-features-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Identify categorical features</a></span></li></ul></li><li><span><a href=\"#Handling-categorical-target\" data-toc-modified-id=\"Handling-categorical-target-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Handling categorical target</a></span></li><li><span><a href=\"#Over-sampling\" data-toc-modified-id=\"Over-sampling-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Over sampling</a></span></li></ul></li><li><span><a href=\"#Hyperparameter-tuning-and-model-selection\" data-toc-modified-id=\"Hyperparameter-tuning-and-model-selection-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Hyperparameter tuning and model selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-the-dictionary-of-classifiers\" data-toc-modified-id=\"Create-the-dictionary-of-classifiers-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Create the dictionary of classifiers</a></span></li><li><span><a href=\"#Create-the-dictionary-of-pipeline\" data-toc-modified-id=\"Create-the-dictionary-of-pipeline-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Create the dictionary of pipeline</a></span></li><li><span><a href=\"#Create-the-dictionary-of-parameter-grids\" data-toc-modified-id=\"Create-the-dictionary-of-parameter-grids-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Create the dictionary of parameter grids</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-parameter-grid-for-logistic-regression\" data-toc-modified-id=\"The-parameter-grid-for-logistic-regression-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>The parameter grid for logistic regression</a></span></li><li><span><a href=\"#The-parameter-grid-for-MLP\" data-toc-modified-id=\"The-parameter-grid-for-MLP-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>The parameter grid for MLP</a></span></li><li><span><a href=\"#The-parameter-grid-for-decision-tree\" data-toc-modified-id=\"The-parameter-grid-for-decision-tree-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>The parameter grid for decision tree</a></span></li><li><span><a href=\"#The-parameter-grid-for-random-forest\" data-toc-modified-id=\"The-parameter-grid-for-random-forest-4.3.4\"><span class=\"toc-item-num\">4.3.4&nbsp;&nbsp;</span>The parameter grid for random forest</a></span></li><li><span><a href=\"#The-parameter-grid-for-xgboost\" data-toc-modified-id=\"The-parameter-grid-for-xgboost-4.3.5\"><span class=\"toc-item-num\">4.3.5&nbsp;&nbsp;</span>The parameter grid for xgboost</a></span></li><li><span><a href=\"#The-parameter-grid-for-SVC\" data-toc-modified-id=\"The-parameter-grid-for-SVC-4.3.6\"><span class=\"toc-item-num\">4.3.6&nbsp;&nbsp;</span>The parameter grid for SVC</a></span></li><li><span><a href=\"#The-parameter-grid-for-KNN\" data-toc-modified-id=\"The-parameter-grid-for-KNN-4.3.7\"><span class=\"toc-item-num\">4.3.7&nbsp;&nbsp;</span>The parameter grid for KNN</a></span></li><li><span><a href=\"#The-parameter-grid-for-GNB\" data-toc-modified-id=\"The-parameter-grid-for-GNB-4.3.8\"><span class=\"toc-item-num\">4.3.8&nbsp;&nbsp;</span>The parameter grid for GNB</a></span></li></ul></li><li><span><a href=\"#Hyperparameter-tuning\" data-toc-modified-id=\"Hyperparameter-tuning-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Hyperparameter tuning</a></span></li><li><span><a href=\"#Model-selection\" data-toc-modified-id=\"Model-selection-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Model selection</a></span></li><li><span><a href=\"#Discussion\" data-toc-modified-id=\"Discussion-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Discussion</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"5\">\n",
    "Machine Learning I (DATS 6202), Fall 2019\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Homework 8 (Solution)\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Data Science, Columbian College of Arts & Sciences, George Washington University\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Author: Yuxiao Huang\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- Apply hyperparameter tuning and model selection to the following 8 classifiers on [Parkinsons Data](https://archive.ics.uci.edu/ml/datasets/parkinsons)\n",
    "    - [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "    - [MLP](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "    - [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "    - [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "    - [XGBoost](https://xgboost.readthedocs.io/en/latest/index.html)\n",
    "    - [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "    - [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "    - [GNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "- Particularly, the code should\n",
    "    - be bug-free (while the output produced by your solution being the same as the provided output does not necessarily mean your code is bug-free, it is very likely that there is a bug in your code when the two kinds of output are different)\n",
    "    - be commented\n",
    "- **Marks will be deducted if the above requirements (for the code) are not met**\n",
    "- Submit an ipynb file named homework_8.ipynb to [blackboard](https://blackboard.gwu.edu) folder /Assignments/Homework_8/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "Students are expected to understand:\n",
    "- how to use the combination of Pipeline and GridSearchCV for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "# Implement me\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data', \n",
    "                 header=0)\n",
    "\n",
    "# Specify the name of the columns\n",
    "df.columns = ['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP', 'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5', 'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA', 'spread1', 'spread2', 'D2', 'PPE']\n",
    "\n",
    "# Specify the name of the target\n",
    "target = 'status'\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove column 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0      119.992       157.302        74.997         0.00784           0.00007   \n",
       "1      122.400       148.650       113.819         0.00968           0.00008   \n",
       "2      116.682       131.111       111.555         0.01050           0.00009   \n",
       "3      116.676       137.871       111.366         0.00997           0.00009   \n",
       "4      116.014       141.781       110.655         0.01284           0.00011   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
       "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
       "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
       "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
       "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
       "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement me\n",
    "df = df[df.columns[1:]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing value\n",
    "Reference: The code in the two cells below is from Midterm_solution.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The missing value checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_checker(df):\n",
    "    \"\"\"\n",
    "    The missing value checker\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    The variables with missing value and their proportion of missing value\n",
    "    \"\"\"\n",
    "    \n",
    "    variable_proportion = [[variable, df[variable].isna().sum() / df.shape[0]] \n",
    "                           for variable in df.columns \n",
    "                           if df[variable].isna().sum() > 0]\n",
    "\n",
    "    print('%-30s' % 'Variable with missing values', 'Proportion of missing values')\n",
    "    for variable, proportion in sorted(variable_proportion, key=lambda x : x[1]):\n",
    "        print('%-30s' % variable, proportion)\n",
    "        \n",
    "    return variable_proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify variables with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable with missing values   Proportion of missing values\n"
     ]
    }
   ],
   "source": [
    "variable_proportion = missing_value_checker(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement me\n",
    "X = df.drop(columns = target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The categorical feature checker\n",
    "Reference: The code in the two cells below is from Midterm_solution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_feature_checker(df, target, dtype):\n",
    "    \"\"\"\n",
    "    The categorical feature checker\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "    target : the target\n",
    "    dtype : the type of the feature\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    The categorical features and their number of unique value\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_number = [[feature, df[feature].nunique()] \n",
    "                      for feature in df.columns \n",
    "                      if feature != target and df[feature].dtype.name == dtype]\n",
    "    \n",
    "    print('%-30s' % 'Categorical feature', 'Number of unique value')\n",
    "    for feature, number in sorted(feature_number, key=lambda x : x[1]):\n",
    "        print('%-30s' % feature, number)\n",
    "    \n",
    "    return feature_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical feature            Number of unique value\n"
     ]
    }
   ],
   "source": [
    "feature_number = categorical_feature_checker(X, target, 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    147\n",
       "0     48\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the unique value and their number for the target\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    147\n",
       "0    147\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# RandomOverSampler (with random_state=0)\n",
    "# Implement me\n",
    "ros = RandomOverSampler()\n",
    "X, y = ros.fit_sample(X,y)\n",
    "\n",
    "pd.DataFrame(data=y, columns=[target])[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning and model selection\n",
    "In this section\n",
    "- we first use the combination of Pipeline and GridSearchCV to fine tune the hyperparameters of 5 classifiers\n",
    "- we then select the best model across the 8 classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of classifiers\n",
    "- In the dictionary:\n",
    "    - the key is the acronym of the classifier\n",
    "    - the value is the classifier\n",
    "\n",
    "- You may have to install XGBoost. If you get an error saying \"ModuleNotFoundError: No module named 'xgboost'\", run the appropriate command below\n",
    "- If you are using anaconda, run\n",
    "    - conda install -c conda-forge xgboost\n",
    "- If you are using plain python installation, run\n",
    "    - pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clfs = {'lr': LogisticRegression(random_state=0),\n",
    "        'mlp': MLPClassifier(random_state=0),\n",
    "        'dt': DecisionTreeClassifier(random_state=0),\n",
    "        'rf': RandomForestClassifier(random_state=0),\n",
    "        'xgb': XGBClassifier(seed=0),\n",
    "        'svc': SVC(random_state=0),\n",
    "        'knn': KNeighborsClassifier(),\n",
    "        'gnb': GaussianNB()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of pipeline\n",
    "In the dictionary:\n",
    "- the key is the acronym of the classifier\n",
    "- the value is the pipeline (with StandardScaler and the classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_clfs = {}\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    # Implement me\n",
    "    pipe_clfs[name] = Pipeline([('StandardScaler',StandardScaler()),('clf',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(memory=None,\n",
       "          steps=[('StandardScaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=100,\n",
       "                                     multi_class='warn', n_jobs=None,\n",
       "                                     penalty='l2', random_state=0, solver='warn',\n",
       "                                     tol=0.0001, verbose=0, warm_start=False))],\n",
       "          verbose=False), 'mlp': Pipeline(memory=None,\n",
       "          steps=[('StandardScaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                early_stopping=False, epsilon=1e-08,\n",
       "                                hidden_layer_sizes=(100,),\n",
       "                                learning_rate='constant',\n",
       "                                learning_rate_init=0.001, max_iter=200,\n",
       "                                momentum=0.9, n_iter_no_change=10,\n",
       "                                nesterovs_momentum=True, power_t=0.5,\n",
       "                                random_state=0, shuffle=True, solver='adam',\n",
       "                                tol=0.0001, validation_fraction=0.1,\n",
       "                                verbose=False, warm_start=False))],\n",
       "          verbose=False), 'dt': Pipeline(memory=None,\n",
       "          steps=[('StandardScaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
       "                                         max_depth=None, max_features=None,\n",
       "                                         max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         presort=False, random_state=0,\n",
       "                                         splitter='best'))],\n",
       "          verbose=False), 'rf': Pipeline(memory=None,\n",
       "          steps=[('StandardScaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                         criterion='gini', max_depth=None,\n",
       "                                         max_features='auto',\n",
       "                                         max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators='warn', n_jobs=None,\n",
       "                                         oob_score=False, random_state=0,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False), 'xgb': Pipeline(memory=None,\n",
       "          steps=[('StandardScaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                colsample_bylevel=1, colsample_bynode=1,\n",
       "                                colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                                max_delta_step=0, max_depth=3,\n",
       "                                min_child_weight=1, missing=None,\n",
       "                                n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                objective='binary:logistic', random_state=0,\n",
       "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                                seed=0, silent=None, subsample=1,\n",
       "                                verbosity=1))],\n",
       "          verbose=False), 'svc': Pipeline(memory=None,\n",
       "          steps=[('StandardScaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                      decision_function_shape='ovr', degree=3,\n",
       "                      gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                      probability=False, random_state=0, shrinking=True,\n",
       "                      tol=0.001, verbose=False))],\n",
       "          verbose=False), 'knn': Pipeline(memory=None,\n",
       "          steps=[('StandardScaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                       metric='minkowski', metric_params=None,\n",
       "                                       n_jobs=None, n_neighbors=5, p=2,\n",
       "                                       weights='uniform'))],\n",
       "          verbose=False), 'gnb': Pipeline(memory=None,\n",
       "          steps=[('StandardScaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf', GaussianNB(priors=None, var_smoothing=1e-09))],\n",
       "          verbose=False)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of parameter grids\n",
    "In the dictionary:\n",
    "- the key is the acronym of the classifier\n",
    "- the value is the parameter grid of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for logistic regression\n",
    "The hyperparameters we want to fine tune are:\n",
    "- multi_class\n",
    "- solver\n",
    "- C\n",
    "\n",
    "Here we need to use two dictionaries in the parameter grid since 'multinomial' (multi_class) does not support 'liblinear' (solver). See details of the meaning of the hyperparametes in [sklearn logistic regression documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "param_grid = [{'clf__multi_class': ['ovr'], \n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'clf__C': C_range},\n",
    "              \n",
    "              {'clf__multi_class': ['multinomial'],\n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'clf__C': C_range}]\n",
    "\n",
    "param_grids['lr'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for MLP\n",
    "The hyperparameters we want to fine tune are:\n",
    "- hidden_layer_sizes\n",
    "- activation\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn multi-layer perceptron documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__hidden_layer_sizes': [10, 100],\n",
    "               'clf__activation': ['identity', 'logistic', 'tanh', 'relu']}]\n",
    "\n",
    "param_grids['mlp'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for decision tree\n",
    "The hyperparameters we want to fine tune are:\n",
    "- min_samples_split\n",
    "- min_samples_leaf\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn decision tree documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "\n",
    "param_grids['dt'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for random forest\n",
    "The hyperparameters we want to fine tune are:\n",
    "- n_estimators\n",
    "- min_samples_split\n",
    "- min_samples_leaf\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn random forest documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__n_estimators': [10, 100],\n",
    "               'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "\n",
    "param_grids['rf'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for xgboost\n",
    "The hyperparameters we want to fine tune are:\n",
    "- eta\n",
    "- gamma\n",
    "- lambda\n",
    "\n",
    "See details of the meaning of the hyperparametes in [XGBoost documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__eta': [10 ** i for i in range(-4, 1)],\n",
    "               'clf__gamma': [0, 10, 100],\n",
    "               'clf__lambda': [10 ** i for i in range(-4, 5)]}]\n",
    "\n",
    "param_grids['xgb'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for SVC\n",
    "The hyperparameters we want to fine tune are:\n",
    "- C\n",
    "- gamma\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn SVC documentation](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__C': [10 ** i for i in range(-4, 5)],\n",
    "               'clf__gamma': ['auto', 'scale']}]\n",
    "\n",
    "param_grids['svc'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for KNN\n",
    "The hyperparameters we want to fine tune are:\n",
    "- n_neighbors\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn KNN documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__n_neighbors': list(range(1, 11))}]\n",
    "\n",
    "param_grids['knn'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for GNB\n",
    "The hyperparameters we want to fine tune are:\n",
    "- var_smoothing\n",
    "\n",
    "See details of the meaning of the hyperparametes in [sklearn GNB documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__var_smoothing': [10 ** i for i in range(-10, -7)]}]\n",
    "\n",
    "param_grids['gnb'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "Here we use two functions for hyperparameter tuning:\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html): Exhaustive search over specified parameter values for an estimator\n",
    "- [StratifiedKFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html): Stratified K-Folds cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('StandardScaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=0, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_clfs['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clf__multi_class': ['ovr'],\n",
       "  'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
       "  'clf__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
       " {'clf__multi_class': ['multinomial'],\n",
       "  'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
       "  'clf__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grids['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# The list of [best_score_, best_params_, best_estimator_]\n",
    "best_score_param_estimators = []\n",
    "\n",
    "# For each classifier\n",
    "for name in pipe_clfs.keys():\n",
    "    # GridSearchCV\n",
    "    # Implement me\n",
    "    gs = GridSearchCV(estimator=pipe_clfs[name],\n",
    "                      param_grid=param_grids[name],\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=1,\n",
    "                      iid=False,\n",
    "                      cv=StratifiedKFold(n_splits=5,\n",
    "                                         shuffle=True,\n",
    "                                         random_state=0))\n",
    "    # Fit the pipeline\n",
    "    # Implement me\n",
    "    gs = gs.fit(X,y)\n",
    "    \n",
    "    # Update best_score_param_estimators\n",
    "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "Note: You may see different results even when your code is exactly correct. This difference is possibly produced by different versions of sklearn (and in turn their default settings of hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9796551724137931, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.9795402298850574, {'clf__eta': 0.0001, 'clf__gamma': 0, 'clf__lambda': 0.0001}, <class 'xgboost.sklearn.XGBClassifier'>]\n",
      "\n",
      "[0.9729885057471265, {'clf__n_neighbors': 1}, <class 'sklearn.neighbors.classification.KNeighborsClassifier'>]\n",
      "\n",
      "[0.9626436781609196, {'clf__activation': 'relu', 'clf__hidden_layer_sizes': 100}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n",
      "[0.962528735632184, {'clf__C': 100, 'clf__gamma': 'auto'}, <class 'sklearn.svm.classes.SVC'>]\n",
      "\n",
      "[0.9524137931034481, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n",
      "[0.8606896551724137, {'clf__C': 1, 'clf__multi_class': 'multinomial', 'clf__solver': 'newton-cg'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n",
      "[0.7549425287356322, {'clf__var_smoothing': 1e-10}, <class 'sklearn.naive_bayes.GaussianNB'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort best_score_param_estimators in descending order of the best_score_\n",
    "# Implement me\n",
    "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x : x[0], reverse=True)\n",
    "\n",
    "# For each [best_score_, best_params_, best_estimator_]\n",
    "for best_score_param_estimator in best_score_param_estimators:\n",
    "    # Print out [best_score_, best_params_, best_estimator_], where best_estimator_ is a pipeline\n",
    "    # Since we only print out the type of classifier of the pipeline\n",
    "    print([best_score_param_estimator[0], best_score_param_estimator[1], type(best_score_param_estimator[2].named_steps['clf'])], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "The above results show that, SVC has the highest accuracy, followed by xgboost, KNN, random forest, decision tree, MLP, logistic regression and GNB. One thing to keep in mind is that, while SVC can be quite accurate it is much slower than xgboost and random forest. It is why in reality, the two models are much more widely used than SVC, particularly when the dataset is (moderately) large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
