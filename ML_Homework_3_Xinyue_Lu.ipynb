{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Remove-feature-'name'\" data-toc-modified-id=\"Remove-feature-'name'-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Remove feature 'name'</a></span></li><li><span><a href=\"#Get-the-features-and-target\" data-toc-modified-id=\"Get-the-features-and-target-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Get the features and target</a></span></li><li><span><a href=\"#Over-sampling\" data-toc-modified-id=\"Over-sampling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Over sampling</a></span></li><li><span><a href=\"#My-logistic-regression-model-(implemented-using-numpy-array)\" data-toc-modified-id=\"My-logistic-regression-model-(implemented-using-numpy-array)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>My logistic regression model (implemented using numpy array)</a></span></li><li><span><a href=\"#Hypterparameter-tuning-and-model-selection\" data-toc-modified-id=\"Hypterparameter-tuning-and-model-selection-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Hypterparameter tuning and model selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-the-dictionary-of-classifiers\" data-toc-modified-id=\"Create-the-dictionary-of-classifiers-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Create the dictionary of classifiers</a></span></li><li><span><a href=\"#Create-the-dictionary-of-pipeline\" data-toc-modified-id=\"Create-the-dictionary-of-pipeline-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Create the dictionary of pipeline</a></span></li><li><span><a href=\"#Create-the-dictionary-of-parameter-grids\" data-toc-modified-id=\"Create-the-dictionary-of-parameter-grids-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Create the dictionary of parameter grids</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-parameter-grid-for-sklearn-logistic-regression\" data-toc-modified-id=\"The-parameter-grid-for-sklearn-logistic-regression-7.3.1\"><span class=\"toc-item-num\">7.3.1&nbsp;&nbsp;</span>The parameter grid for sklearn logistic regression</a></span></li><li><span><a href=\"#The-parameter-grid-for-MyLogisticRegression\" data-toc-modified-id=\"The-parameter-grid-for-MyLogisticRegression-7.3.2\"><span class=\"toc-item-num\">7.3.2&nbsp;&nbsp;</span>The parameter grid for MyLogisticRegression</a></span></li></ul></li><li><span><a href=\"#Hyperparameter-tuning\" data-toc-modified-id=\"Hyperparameter-tuning-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Hyperparameter tuning</a></span></li><li><span><a href=\"#Model-selection\" data-toc-modified-id=\"Model-selection-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Model selection</a></span></li></ul></li><li><span><a href=\"#Discussion\" data-toc-modified-id=\"Discussion-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Discussion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"5\">\n",
    "Machine Learning I (DATS 6202), Fall 2019\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Homework 3\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Data Science, Columbian College of Arts & Sciences, George Washington University\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Author: Yuxiao Huang\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- Apply Logistic Regression on the [Parkinsons Dataset](https://archive.ics.uci.edu/ml/datasets/parkinsons)\n",
    "- Particularly, you should implement your own logistic regression model (using numpy array)\n",
    "- Complete the missing parts indicated by # Implement me\n",
    "- Particularly, the code should\n",
    "    - be bug-free (while the output produced by your solution being the same as the provided output does not necessarily mean your code is bug-free, it is very likely that there is a bug in your code when the two kinds of output are different)\n",
    "    - be commented\n",
    "- **Marks will be deducted if the above requirements (for the code) are not met**\n",
    "- Submit an ipynb file named homework_3.ipynb to [blackboard](https://blackboard.gwu.edu) folder /Assignments/Homework_3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer    ...     \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374    ...      \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134    ...      \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233    ...      \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492    ...      \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425    ...      \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Implement me\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data',\n",
    "                 header= 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove feature 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0      119.992       157.302        74.997         0.00784           0.00007   \n",
       "1      122.400       148.650       113.819         0.00968           0.00008   \n",
       "2      116.682       131.111       111.555         0.01050           0.00009   \n",
       "3      116.676       137.871       111.366         0.00997           0.00009   \n",
       "4      116.014       141.781       110.655         0.01284           0.00011   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)    ...     \\\n",
       "0   0.00370   0.00554     0.01109       0.04374             0.426    ...      \n",
       "1   0.00465   0.00696     0.01394       0.06134             0.626    ...      \n",
       "2   0.00544   0.00781     0.01633       0.05233             0.482    ...      \n",
       "3   0.00502   0.00698     0.01505       0.05492             0.517    ...      \n",
       "4   0.00655   0.00908     0.01966       0.06425             0.584    ...      \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement me\n",
    "df = df.drop(columns=['name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The target\n",
    "targets = 'status'\n",
    "\n",
    "# Implement me\n",
    "X = df.drop(columns=[targets]).values\n",
    "y = df[targets].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    147\n",
       "0    147\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Implement me\n",
    "# RandomOverSampler (with random_state=0)\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X, y = ros.fit_sample(X, y)\n",
    "\n",
    "pd.DataFrame(data=y, columns=['target'])['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My logistic regression model (implemented using numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "\n",
    "class MyLogisticRegression(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"My logistic regression model (implemented using numpy array)\"\"\"\n",
    "    \n",
    "    def __init__(self, n_iter=100, eta=10 ** -2, C=1, random_state=0):\n",
    "        # The number of iterations\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "        # The learning rate\n",
    "        self.eta = eta\n",
    "        \n",
    "        # The regularization parameter\n",
    "        self.C = C\n",
    "        \n",
    "        # The random state\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # The class labels\n",
    "        self.classes = None\n",
    "        \n",
    "        # The cost\n",
    "        self.cost = None\n",
    "        \n",
    "        # The parameters\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        The fit function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature matrix\n",
    "        y : the target vector\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the class labels\n",
    "        self.classes = np.unique(y)\n",
    "        \n",
    "        # Get the one-hot-encoded target matrix\n",
    "        # Here y_one_hot_encode is a X.shape[0] by len(self.classes) matrix\n",
    "        y_one_hot_encode = pd.get_dummies(y).values\n",
    "                \n",
    "        # Initialize the cost\n",
    "        self.cost = []\n",
    "        \n",
    "        # The random number generator\n",
    "        self.rgen = np.random.RandomState(seed=self.random_state)\n",
    "        \n",
    "        # Initialize the weight for features x0 (the dummy feature), x1, x2, ..., xn (with respect to each class)\n",
    "        # Here self.w is a X.shape[1] + 1 by len(self.classes) matrix\n",
    "        self.w = self.rgen.normal(loc=0.0, scale=0.01, size=(X.shape[1] + 1, len(self.classes)))\n",
    "\n",
    "        # For each iteration\n",
    "        for _ in range(self.n_iter):\n",
    "            # Implement me\n",
    "            # Get the net input\n",
    "            # Here net_input is a X.shape[0] by len(self.classes) matrix\n",
    "            net_input = self.net_input(X)\n",
    "            \n",
    "            # Implement me\n",
    "            # Get the sigmoid\n",
    "            # Here sigmoid is a X.shape[0] by len(self.classes) matrix\n",
    "            sigmoid = self.sigmoid(net_input)\n",
    "            \n",
    "            # Implement me\n",
    "            # Get the errors\n",
    "            # Here errors is a X.shape[0] by len(self.classes) matrix     \n",
    "            errors = y_one_hot_encode - sigmoid\n",
    "            \n",
    "            # Get the mean squared error (mse)\n",
    "            mse = (errors ** 2).sum()\n",
    "            \n",
    "            # Update the cost\n",
    "            self.cost.append(mse)\n",
    "            \n",
    "            # Implement me\n",
    "            # Update the weight of features x1, x2, ..., xn (with respect to each class)\n",
    "            self.w[1:,] += self.eta * (np.matmul(X.T, errors)- 2* self.C* self.w[1:]) ## regulization: cost+ sum(wi**2)\n",
    "            \n",
    "            # Implement me\n",
    "            # Update the weight of the dummy feature, x0 (with respect to each class)\n",
    "            self.w[0, :] += self.eta * errors.sum(axis = 0)\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"\n",
    "        Get the net input\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature matrix\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The net input\n",
    "       \n",
    "        \"\"\"\n",
    "        \n",
    "        # Implement me\n",
    "        return X.dot(self.w[1:,]) + self.w[0,]\n",
    "    \n",
    "    def sigmoid(self, net_input):\n",
    "        \"\"\"\n",
    "        Get the sigmoid\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        net_input : the net input\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The sigmoid\n",
    "       \n",
    "        \"\"\"\n",
    "        \n",
    "        return 1 / (1 + (np.exp(np.clip(-net_input, -250, 250))))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        The predict function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature matrix\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The class with the maximum probability\n",
    "        \"\"\"\n",
    "        \n",
    "        # Implement me\n",
    "        # Get the net input\n",
    "        net_input = self.net_input(X)\n",
    "        \n",
    "        # Implement me\n",
    "        # Get the sigmoid\n",
    "        sigmoid = self.sigmoid(net_input)\n",
    "    \n",
    "        # Return the class with the maximum probability\n",
    "        return np.argmax(sigmoid, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypterparameter tuning and model selection\n",
    "- In this section\n",
    "    - we will first use the combination of pipeline and GridSearchCV to fine tune the hyperparameter of two classifiers:\n",
    "        - [sklearn logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "        - MyLogisticRegression\n",
    "    - we will then select the better model between the two classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of classifiers\n",
    "- In the dictionary:\n",
    "    - the key is the acronym of the classifier\n",
    "    - the value is the classifier (with random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfs = {'lr': LogisticRegression(random_state=0),\n",
    "        'mylr': MyLogisticRegression(random_state=0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of pipeline\n",
    "- In the dictionary:\n",
    "    - the key is the acronym of the classifier\n",
    "    - the value is the pipeline, with StandardScaler and the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_clfs = {}\n",
    "\n",
    "# Implement me\n",
    "for name, clf in clfs.items():\n",
    "    pipe_clfs[name] = Pipeline([('StandardScaler', StandardScaler()), \n",
    "                                ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of parameter grids\n",
    "- In the dictionary:\n",
    "    - the key is the acronym of the classifier\n",
    "    - the value is the parameter grid of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for sklearn logistic regression\n",
    "- The hyperparameters we want to tune are:\n",
    "    - multi_class\n",
    "    - solver\n",
    "    - C\n",
    "\n",
    "- Here we need to use two dictionaries in the parameter grid since 'multinomial' (multi_class) does not support 'liblinear' (solver). See details of the meaning of the hyperparametes in [sklearn logistic regression documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "param_grid = [{'clf__multi_class': ['ovr'], \n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'clf__C': C_range},\n",
    "              {'clf__multi_class': ['multinomial'],\n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'clf__C': C_range}]\n",
    "\n",
    "param_grids['lr'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter grid for MyLogisticRegression\n",
    "- The hyperparameters we want to tune are:\n",
    "    - eta\n",
    "    - C\n",
    "\n",
    "- See details of the meaning of the hyperparametes in the definition of MyLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_range = [10 ** i for i in range(-3, 1)]\n",
    "C_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "param_grid = [{'clf__eta': eta_range,\n",
    "               'clf__C': C_range}]\n",
    "\n",
    "param_grids['mylr'] = param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'mylr'\n",
    "gs = GridSearchCV(estimator=pipe_clfs[name],\n",
    "                      param_grid=param_grids[name],\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      iid=False,\n",
    "                      cv=StratifiedKFold(n_splits=10,\n",
    "                                         random_state=0),\n",
    "                      return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=0, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('StandardScaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('clf',\n",
       "                                        MyLogisticRegression(C=1, eta=0.01,\n",
       "                                                             n_iter=100,\n",
       "                                                             random_state=0))],\n",
       "                                verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid=[{'clf__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000,\n",
       "                                     10000],\n",
       "                          'clf__eta': [0.001, 0.01, 0.1, 1]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "- Here we use two functions for hyperparameter tuning:\n",
    "    - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html): Exhaustive search over specified parameter values for an estimator\n",
    "    - [StratifiedKFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html): Stratified K-Folds cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# The list of [best_score_, best_params_, best_estimator_]\n",
    "best_score_param_estimators = []\n",
    "\n",
    "# For each classifier\n",
    "for name in pipe_clfs.keys():\n",
    "    # Implement me\n",
    "    # GridSearchCV\n",
    "    gs = GridSearchCV(estimator=pipe_clfs[name],\n",
    "                      param_grid=param_grids[name],\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      iid=False,\n",
    "                      cv=StratifiedKFold(n_splits=10,\n",
    "                                         random_state=0),\n",
    "                      return_train_score=True)\n",
    "    # Implement me\n",
    "    # Fit the pipeline\n",
    "    gs = gs.fit(X, y)\n",
    "    \n",
    "    # Update best_score_param_estimators\n",
    "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])\n",
    "    \n",
    "    # Sort cv_results in ascending order of 'rank_test_score' and 'std_test_score'\n",
    "    cv_results = pd.DataFrame.from_dict(gs.cv_results_).sort_values(by=['rank_test_score', 'std_test_score'])\n",
    "    \n",
    "    # Get the important columns in cv_results\n",
    "    important_columns = ['rank_test_score',\n",
    "                         'mean_test_score', \n",
    "                         'std_test_score', \n",
    "                         'mean_train_score', \n",
    "                         'std_train_score',\n",
    "                         'mean_fit_time', \n",
    "                         'std_fit_time',                        \n",
    "                         'mean_score_time', \n",
    "                         'std_score_time']\n",
    "    \n",
    "    # Move the important columns ahead\n",
    "    cv_results = cv_results[important_columns + sorted(list(set(cv_results.columns) - set(important_columns)))]\n",
    "\n",
    "    # Write cv_results file\n",
    "    cv_results.to_csv(path_or_buf=name + '_cv_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1\n",
      "best_score:     0.8207142857142857\n",
      "best_estimator: <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "best_params:    {'clf__C': 10, 'clf__multi_class': 'multinomial', 'clf__solver': 'sag'}\n",
      "\n",
      "Top 2\n",
      "best_score:     0.8107142857142857\n",
      "best_estimator: <class '__main__.MyLogisticRegression'>\n",
      "best_params:    {'clf__C': 0.0001, 'clf__eta': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort best_score_param_estimators in descending order of the best_score_\n",
    "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x : x[0], reverse=True)\n",
    "\n",
    "# Print best_score_param_estimators\n",
    "for rank in range(len(best_score_param_estimators)):\n",
    "    best_score, best_params, best_estimator = best_score_param_estimators[rank]\n",
    "\n",
    "    print('Top', str(rank + 1))    \n",
    "    print('%-15s' % 'best_score:', best_score)\n",
    "    print('%-15s' % 'best_estimator:'.format(20), type(best_estimator.named_steps['clf']))\n",
    "    print('%-15s' % 'best_params:'.format(20), best_params, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "The results above show that, the average accuracy of our model is higher than that of the sklearn model. Moreover, the cv results (in the csv files) show that the standard deviation (of accuracy) of our model is lower than that of the sklearn model. This means that, on the Parkinsons dataset, our model is more accurate and more robust than the sklearn model. This is pretty impressive considering the latter was highly optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
